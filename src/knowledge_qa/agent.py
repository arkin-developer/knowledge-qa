"""LangGraph Agent é›†æˆ"""

from typing import List, Dict, Any, Optional, TypedDict
from langchain_core.documents import Document
from langgraph.graph import StateGraph, END
from pathlib import Path
from langsmith import traceable

from .text_processor import TextProcessor
from .vector_store import VectorStore
from .llms.reader_llm import ReaderLLM, ReaderResult, DocumentFragment
from .llms.qa_llm import QALLM
from .llms.finished_llm import FinishedLLM, FinishedState
from .llms.verify_llm import VerifyLLM, VerifyState
from .file_parser import FileParser
from .log_manager import log
from .config import settings


class KnowledgeQAState(TypedDict):
    """çŸ¥è¯†åº“é—®ç­”çŠ¶æ€"""
    query: str # ç”¨æˆ·çš„åŸå§‹é—®é¢˜
    file_path: Optional[str] # æ–‡ä»¶è·¯å¾„
    mode: str  # "upload", "query"
    context_docs: List[Document] # ä¸Šä¸‹æ–‡æ–‡æ¡£(å‘é‡æ•°æ®åº“çš„æ£€ç´¢ç»“æœ)
    reader_result: Optional[ReaderResult] # é€šè¿‡æœ¬åœ°æ–‡æ¡£æŸ¥è¯¢çš„æ–‡æ¡£ç‰‡æ®µ
    qa_answer: str # QAå¤§æ¨¡å‹çš„å›ç­”
    verify_state: Optional[VerifyState] # é€šè¿‡readeræ¨¡å‹æŸ¥è¯¢çš„èµ„æ–™æ˜¯å¦æ»¡è¶³ç”¨æˆ·é—®é¢˜çš„éªŒè¯çŠ¶æ€
    finished_state: Optional[FinishedState] # åˆ¤æ–­æ™ºèƒ½ä½“æ˜¯å¦å®Œæˆå¤§æ¨¡å‹å›ç­”çš„çŠ¶æ€
    suggestions: Optional[str] # éªŒè¯æ¨¡å‹ç»™å‡ºçš„å»ºè®®ï¼Œå¯ä»¥ä¼ å…¥readeræ¨¡å‹è¿›è¡ŒäºŒæ¬¡æ£€ç´¢
    sources: List[Dict[str, Any]] # å¼•ç”¨ä¿¡æ¯(QAå¤§æ¨¡å‹çš„å›ç­”å¼•ç”¨æ¥æº)
    error: Optional[str] # é”™è¯¯ä¿¡æ¯ï¼Œå¦‚æœå‘ç”Ÿé”™è¯¯ï¼Œåˆ™éœ€è¦å¤„ç†é”™è¯¯
    iteration_count: int # è¿­ä»£æ¬¡æ•°ï¼Œé˜²æ­¢æ— é™å¾ªç¯


class KnowledgeQAAgent:
    """çŸ¥è¯†åº“é—®ç­”Agent"""

    def __init__(self, text_processor: Optional[TextProcessor] = None,
                 vector_store: Optional[VectorStore] = None):
        self.text_processor = text_processor or TextProcessor()
        self.vector_store = vector_store or VectorStore()   

        self.reader_llm = ReaderLLM() # é˜…è¯»æœ¬åœ°æ–‡ä»¶èµ„æ–™çš„å·¥å…·æ¨¡å‹
        self.qa_llm = QALLM() # çŸ¥è¯†åº“é—®ç­”å¤§æ¨¡å‹
        self.finished_llm = FinishedLLM() # åˆ¤æ–­æ™ºèƒ½ä½“æ˜¯å¦å®Œæˆå¤§æ¨¡å‹å›ç­”
        self.verify_llm = VerifyLLM() # éªŒè¯èµ„æ–™æ˜¯å¦è¶³å¤Ÿçš„æ¨¡å‹

        # æ„å»ºLangGraph
        self.graph = self._build_graph()
        self.app = self.graph.compile()

        log.info("KnowledgeQAAgent åˆå§‹åŒ–å®Œæˆ")

    def _build_graph(self) -> StateGraph:
        """æ„å»ºreason-actionæ¶æ„çš„å·¥ä½œæµå›¾"""
        workflow = StateGraph(KnowledgeQAState)

        # æ·»åŠ æ ¸å¿ƒèŠ‚ç‚¹
        workflow.add_node("process_file", self._process_file_node)
        workflow.add_node("store_document", self._store_document_node)
        workflow.add_node("retrieve_context", self._retrieve_context_node)
        workflow.add_node("generate_answer", self._generate_answer_node)
        workflow.add_node("check_finished", self._check_finished_node)
        workflow.add_node("reader_search", self._reader_search_node)
        workflow.add_node("verify_context", self._verify_context_node)
        workflow.add_node("handle_error", self._handle_error_node)

        # è®¾ç½®è¾¹è¿æ¥
        workflow.add_edge("process_file", "store_document")
        workflow.add_edge("retrieve_context", "generate_answer")
        workflow.add_edge("generate_answer", "check_finished")
        workflow.add_edge("reader_search", "verify_context")
        workflow.add_edge("handle_error", END)

        # æ–‡æ¡£å­˜å‚¨åçš„æ¡ä»¶è·¯ç”±
        workflow.add_conditional_edges(
            "store_document",
            self._route_after_store,
            {
                "continue_query": "retrieve_context",
                "end": END
            }
        )

        # å®Œæˆæ£€æŸ¥åçš„æ¡ä»¶è·¯ç”±
        workflow.add_conditional_edges(
            "check_finished",
            self._route_after_finished_check,
            {
                "finished": END,
                "need_search": "reader_search",
                "error": "handle_error"
            }
        )

        # éªŒè¯åçš„æ¡ä»¶è·¯ç”±
        workflow.add_conditional_edges(
            "verify_context",
            self._route_after_verify,
            {
                "satisfied": "generate_answer",
                "need_more": "reader_search",
                "error": "handle_error"
            }
        )

        # ç»Ÿä¸€å…¥å£è·¯ç”±
        def route(state: KnowledgeQAState) -> str:
            if state.get("error"):
                return "handle_error"
            elif state.get("mode") == "upload":
                return "process_file"
            elif state.get("mode") == "query":
                return "retrieve_context"
            else:
                return "handle_error"

        workflow.set_conditional_entry_point(route)

        return workflow

    def _route_after_store(self, state: KnowledgeQAState) -> str:
        """æ–‡æ¡£å­˜å‚¨åçš„è·¯ç”±å†³ç­–"""
        return "end"  # ä¸Šä¼ æ¨¡å¼ç›´æ¥ç»“æŸ

    @traceable(name="check_finished_node")
    def _check_finished_node(self, state: KnowledgeQAState) -> KnowledgeQAState:
        """æ£€æŸ¥å›ç­”æ˜¯å¦å®Œæˆçš„èŠ‚ç‚¹"""
        log.info("æ‰§è¡Œå®ŒæˆçŠ¶æ€æ£€æŸ¥")
        
        try:
            query = state["query"]
            answer = state["qa_answer"]
            
            # è®°å½•FinishedLLMçš„è¾“å…¥
            log.info("=" * 50)
            log.info("ğŸ” FinishedLLM è¾“å…¥:")
            log.info(f"  é—®é¢˜: {query}")
            log.info(f"  å½“å‰å›ç­”: {answer[:200]}{'...' if len(answer) > 200 else ''}")
            log.info("=" * 50)
            
            # ä½¿ç”¨finished_llmåˆ¤æ–­æ˜¯å¦å®Œæˆ
            finished_state = self.finished_llm.generate(query, answer)
            state["finished_state"] = finished_state
            
            # å¤„ç†è¿”å›çš„å­—å…¸æ ¼å¼
            if isinstance(finished_state, dict):
                finished = finished_state.get("finished", False)
                reason = finished_state.get("reason", "")
            else:
                finished = finished_state.finished
                reason = finished_state.reason
            
            # è®°å½•FinishedLLMçš„è¾“å‡º
            log.info("=" * 50)
            log.info("ğŸ” FinishedLLM è¾“å‡º:")
            log.info(f"  å®ŒæˆçŠ¶æ€: {finished}")
            log.info(f"  åˆ¤æ–­åŸå› : {reason}")
            log.info("=" * 50)
                
            log.info(f"å®ŒæˆçŠ¶æ€æ£€æŸ¥ç»“æœ: {finished}, åŸå› : {reason}")
            
        except Exception as e:
            log.error(f"å®ŒæˆçŠ¶æ€æ£€æŸ¥å¤±è´¥: {e}")
            state["error"] = f"å®ŒæˆçŠ¶æ€æ£€æŸ¥å¤±è´¥: {str(e)}"
        
        return state

    @traceable(name="reader_search_node")
    def _reader_search_node(self, state: KnowledgeQAState) -> KnowledgeQAState:
        """Readeræœç´¢èŠ‚ç‚¹"""
        log.info("æ‰§è¡ŒReaderæœç´¢")
        
        try:
            query = state["query"]
            suggestions = state.get("suggestions")
            
            # è®°å½•ReaderLLMçš„è¾“å…¥
            log.info("=" * 50)
            log.info("ğŸ“š ReaderLLM è¾“å…¥:")
            if suggestions:
                log.info(f"  æœç´¢å»ºè®®: {suggestions}")
                log.info(f"  åŸå§‹é—®é¢˜: {query}")
            else:
                log.info(f"  æœç´¢é—®é¢˜: {query}")
            log.info("=" * 50)
            
            # ä½¿ç”¨reader_llmæœç´¢æ–‡æ¡£ç‰‡æ®µ
            if suggestions:
                # å¦‚æœæœ‰å»ºè®®ï¼Œä½¿ç”¨å»ºè®®è¿›è¡ŒäºŒæ¬¡æœç´¢
                reader_result = self.reader_llm.generate(suggestions=suggestions)
            else:
                # é¦–æ¬¡æœç´¢
                reader_result = self.reader_llm.generate(query=query)
            
            state["reader_result"] = reader_result
            
            # è®°å½•ReaderLLMçš„è¾“å‡º
            log.info("=" * 50)
            log.info("ğŸ“š ReaderLLM è¾“å‡º:")
            log.info(f"  æ‰¾åˆ°ç‰‡æ®µæ•°é‡: {len(reader_result.fragments)}")
            for i, fragment in enumerate(reader_result.fragments, 1):
                log.info(f"  ç‰‡æ®µ{i}: {fragment.filename} (è¡Œ{fragment.start_line}-{fragment.end_line})")
                log.info(f"    å†…å®¹: {fragment.content[:100]}{'...' if len(fragment.content) > 100 else ''}")
            log.info("=" * 50)
            
            log.info(f"Readeræœç´¢å®Œæˆï¼Œæ‰¾åˆ° {len(reader_result.fragments)} ä¸ªç‰‡æ®µ")
            
        except Exception as e:
            log.error(f"Readeræœç´¢å¤±è´¥: {e}")
            state["error"] = f"Readeræœç´¢å¤±è´¥: {str(e)}"
        
        return state

    @traceable(name="verify_context_node")
    def _verify_context_node(self, state: KnowledgeQAState) -> KnowledgeQAState:
        """éªŒè¯ä¸Šä¸‹æ–‡èŠ‚ç‚¹"""
        log.info("æ‰§è¡Œä¸Šä¸‹æ–‡éªŒè¯")
        
        try:
            query = state["query"]
            answer = state["qa_answer"]
            reader_result = state["reader_result"]
            
            # æ„å»ºä¸Šä¸‹æ–‡ä¿¡æ¯
            context_text = "\n".join([fragment.content for fragment in reader_result.fragments])
            
            # è®°å½•VerifyLLMçš„è¾“å…¥
            log.info("=" * 50)
            log.info("âœ… VerifyLLM è¾“å…¥:")
            log.info(f"  é—®é¢˜: {query}")
            log.info(f"  å½“å‰å›ç­”: {answer[:200]}{'...' if len(answer) > 200 else ''}")
            log.info(f"  æ£€ç´¢åˆ°çš„ä¸Šä¸‹æ–‡: {context_text[:200]}{'...' if len(context_text) > 200 else ''}")
            log.info("=" * 50)
            
            # ä½¿ç”¨verify_llméªŒè¯èµ„æ–™æ˜¯å¦è¶³å¤Ÿ
            verify_state = self.verify_llm.generate(query, answer, context_text)
            state["verify_state"] = verify_state
            
            # å¤„ç†å­—å…¸æ ¼å¼çš„è¿”å›å€¼
            if isinstance(verify_state, dict):
                state["suggestions"] = verify_state.get("suggestions")
                satisfied = verify_state.get("satisfied", False)
                reason = verify_state.get("reason", "")
            else:
                state["suggestions"] = verify_state.suggestions
                satisfied = verify_state.satisfied
                reason = verify_state.reason
            
            # è®°å½•VerifyLLMçš„è¾“å‡º
            log.info("=" * 50)
            log.info("âœ… VerifyLLM è¾“å‡º:")
            log.info(f"  æ˜¯å¦æ»¡è¶³: {satisfied}")
            log.info(f"  åˆ¤æ–­åŸå› : {reason}")
            if state["suggestions"]:
                log.info(f"  æ”¹è¿›å»ºè®®: {state['suggestions']}")
            log.info("=" * 50)
            
            log.info(f"éªŒè¯ç»“æœ: {satisfied}, åŸå› : {reason}")
            
        except Exception as e:
            log.error(f"ä¸Šä¸‹æ–‡éªŒè¯å¤±è´¥: {e}")
            state["error"] = f"ä¸Šä¸‹æ–‡éªŒè¯å¤±è´¥: {str(e)}"
        
        return state

    def _route_after_finished_check(self, state: KnowledgeQAState) -> str:
        """å®Œæˆæ£€æŸ¥åçš„è·¯ç”±å†³ç­–"""
        if state.get("error"):
            return "error"
        
        finished_state = state.get("finished_state")
        if not finished_state:
            return "error"
        
        # æ£€æŸ¥è¿­ä»£æ¬¡æ•°ï¼Œé˜²æ­¢æ— é™å¾ªç¯
        iteration_count = state.get("iteration_count", 0)
        if iteration_count >= 5:  # æœ€å¤š5æ¬¡è¿­ä»£
            log.warning("è¾¾åˆ°æœ€å¤§è¿­ä»£æ¬¡æ•°ï¼Œå¼ºåˆ¶ç»“æŸ")
            return "finished"
        
        # å¤„ç†å­—å…¸æ ¼å¼çš„è¿”å›å€¼
        if isinstance(finished_state, dict):
            finished = finished_state.get("finished", False)
        else:
            finished = finished_state.finished
            
        if finished:
            return "finished"
        else:
            # éœ€è¦è¿›ä¸€æ­¥æœç´¢
            return "need_search"

    def _route_after_verify(self, state: KnowledgeQAState) -> str:
        """éªŒè¯åçš„è·¯ç”±å†³ç­–"""
        if state.get("error"):
            return "error"
        
        verify_state = state.get("verify_state")
        if not verify_state:
            return "error"
        
        # å¤„ç†å­—å…¸æ ¼å¼çš„è¿”å›å€¼
        if isinstance(verify_state, dict):
            satisfied = verify_state.get("satisfied", False)
        else:
            satisfied = verify_state.satisfied
            
        if satisfied:
            # èµ„æ–™è¶³å¤Ÿï¼Œé‡æ–°ç”Ÿæˆå›ç­”
            return "satisfied"
        else:
            # éœ€è¦æ›´å¤šèµ„æ–™
            return "need_more"

    @traceable(name="process_file_node")
    def _process_file_node(self, state: KnowledgeQAState) -> KnowledgeQAState:
        """æ–‡ä»¶å¤„ç†èŠ‚ç‚¹"""
        log.info("æ‰§è¡Œæ–‡ä»¶å¤„ç†")

        try:
            file_path = state.get("file_path")
            if not file_path or not Path(file_path).exists():
                state["error"] = "æ–‡ä»¶ä¸å­˜åœ¨æˆ–è·¯å¾„æ— æ•ˆ"
                return state

            # æ–‡ä»¶å¤„ç†
            log.info(f"å¼€å§‹è§£ææ–‡ä»¶: {file_path}")
            text = FileParser.parse_file(file_path)
            log.info(f"æ–‡ä»¶è§£æå®Œæˆï¼Œæ–‡æœ¬é•¿åº¦: {len(text)} å­—ç¬¦")

            # æ–‡æœ¬åˆ†æ®µ
            log.info("å¼€å§‹æ–‡æœ¬åˆ†æ®µ")
            documents = self.text_processor.split_text(text)
            log.info(f"æ–‡æœ¬åˆ†æ®µå®Œæˆï¼Œå…± {len(documents)} æ®µ")

            state["context_docs"] = documents
            log.info("æ–‡ä»¶å¤„ç†å®Œæˆ")

        except Exception as e:
            log.error(f"æ–‡ä»¶å¤„ç†å¤±è´¥: {e}")
            state["error"] = f"æ–‡ä»¶å¤„ç†å¤±è´¥: {str(e)}"

        return state

    @traceable(name="store_document_node")
    def _store_document_node(self, state: KnowledgeQAState) -> KnowledgeQAState:
        """æ–‡æ¡£å­˜å‚¨èŠ‚ç‚¹"""
        log.info("æ‰§è¡Œæ–‡æ¡£å­˜å‚¨")

        try:
            documents = state.get("context_docs", [])
            if not documents:
                state["error"] = "æ²¡æœ‰å¯å­˜å‚¨çš„æ–‡æ¡£"
                return state

            # å‘é‡åŒ–å¹¶å…¥åº“
            log.info("å¼€å§‹å‘é‡åŒ–å¹¶å…¥åº“")
            self.vector_store.add_documents(documents, batch_size=10)
            log.info("å‘é‡åŒ–å…¥åº“å®Œæˆ")

            # ä¿å­˜å‘é‡åº“
            self.vector_store.save_vector_store()
            log.info("å‘é‡åº“ä¿å­˜å®Œæˆ")

        except Exception as e:
            log.error(f"æ–‡æ¡£å­˜å‚¨å¤±è´¥: {e}")
            state["error"] = f"æ–‡æ¡£å­˜å‚¨å¤±è´¥: {str(e)}"

        return state

    @traceable(name="retrieve_context_node")
    def _retrieve_context_node(self, state: KnowledgeQAState) -> KnowledgeQAState:
        """ä¸Šä¸‹æ–‡æ£€ç´¢èŠ‚ç‚¹"""
        log.info("æ‰§è¡Œä¸Šä¸‹æ–‡æ£€ç´¢")

        try:
            query = state["query"]
            if not query or not query.strip():
                state["error"] = "æŸ¥è¯¢å†…å®¹ä¸ºç©º"
                return state

            context_docs = self.vector_store.similarity_search(query, k=settings.search_k)
            state["context_docs"] = context_docs

            log.info(f"æ£€ç´¢åˆ° {len(context_docs)} ä¸ªç›¸å…³æ–‡æ¡£")

        except Exception as e:
            log.error(f"ä¸Šä¸‹æ–‡æ£€ç´¢å¤±è´¥: {e}")
            state["error"] = f"ä¸Šä¸‹æ–‡æ£€ç´¢å¤±è´¥: {str(e)}"
            state["context_docs"] = []

        return state

    @traceable(name="generate_answer_node")
    def _generate_answer_node(self, state: KnowledgeQAState) -> KnowledgeQAState:
        """ç­”æ¡ˆç”ŸæˆèŠ‚ç‚¹"""
        log.info("æ‰§è¡Œç­”æ¡ˆç”Ÿæˆ")

        try:
            query = state["query"]
            context_docs = state["context_docs"]
            reader_result = state.get("reader_result")

            # è®°å½•QALLMçš„è¾“å…¥
            log.info("=" * 50)
            log.info("ğŸ¤– QALLM è¾“å…¥:")
            log.info(f"  é—®é¢˜: {query}")
            log.info(f"  å‘é‡æ£€ç´¢æ–‡æ¡£æ•°é‡: {len(context_docs)}")
            if reader_result and reader_result.fragments:
                log.info(f"  Readeræ£€ç´¢ç‰‡æ®µæ•°é‡: {len(reader_result.fragments)}")
                for i, fragment in enumerate(reader_result.fragments, 1):
                    log.info(f"    ç‰‡æ®µ{i}: {fragment.filename} (è¡Œ{fragment.start_line}-{fragment.end_line})")
            else:
                log.info("  Readeræ£€ç´¢ç‰‡æ®µ: æ— ")
            log.info("=" * 50)

            # è°ƒç”¨LLMç”Ÿæˆå›ç­”ï¼Œä¼ å…¥reader_result
            result = self.qa_llm.generate(query, context_docs, reader_result)

            state["qa_answer"] = result["answer"]
            state["sources"] = result["sources"]

            # è®°å½•QALLMçš„è¾“å‡º
            log.info("=" * 50)
            log.info("ğŸ¤– QALLM è¾“å‡º:")
            log.info(f"  ç”Ÿæˆå›ç­”: {result['answer'][:200]}{'...' if len(result['answer']) > 200 else ''}")
            log.info(f"  å¼•ç”¨æ¥æºæ•°é‡: {len(result['sources'])}")
            for i, source in enumerate(result["sources"], 1):
                log.info(f"    æ¥æº{i}: {source.get('content', '')[:50]}{'...' if len(source.get('content', '')) > 50 else ''}")
            log.info("=" * 50)

            # ç»“æœåå¤„ç†
            answer = state["qa_answer"]
            if len(answer) < 10:
                state["qa_answer"] = "æŠ±æ­‰ï¼Œæˆ‘æ— æ³•æä¾›å®Œæ•´çš„å›ç­”ã€‚"

            # ç¡®ä¿å¼•ç”¨æ ¼å¼æ­£ç¡®
            sources = state["sources"]
            for i, source in enumerate(sources, 1):
                source["index"] = i

            # å¢åŠ è¿­ä»£æ¬¡æ•°
            state["iteration_count"] = state.get("iteration_count", 0) + 1

            log.info("ç­”æ¡ˆç”Ÿæˆå®Œæˆ")

        except Exception as e:
            log.error(f"ç­”æ¡ˆç”Ÿæˆå¤±è´¥: {e}")
            state["error"] = f"ç­”æ¡ˆç”Ÿæˆå¤±è´¥: {str(e)}"
            state["qa_answer"] = "æŠ±æ­‰ï¼Œæˆ‘æ— æ³•å›ç­”è¿™ä¸ªé—®é¢˜ã€‚"
            state["sources"] = []

        return state

    @traceable(name="handle_error_node")
    def _handle_error_node(self, state: KnowledgeQAState) -> KnowledgeQAState:
        """é”™è¯¯å¤„ç†èŠ‚ç‚¹"""
        log.error("æ‰§è¡Œé”™è¯¯å¤„ç†")

        error_msg = state.get("error", "æœªçŸ¥é”™è¯¯")
        log.error(f"å¤„ç†é”™è¯¯: {error_msg}")

        # è®¾ç½®é»˜è®¤é”™è¯¯å“åº”
        state["answer"] = f"å¤„ç†è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {error_msg}"
        state["sources"] = []

        return state

    @traceable(name="chat")
    def chat(self, query: str, file_path: Optional[str] = None) -> Dict[str, Any]:
        """å¯¹è¯æ¥å£"""
        log.info(f"å¼€å§‹å¤„ç†ç”¨æˆ·è¾“å…¥ - æŸ¥è¯¢: {query}, æ–‡ä»¶: {file_path}")

        # ç¡®å®šæ¨¡å¼
        if file_path and Path(file_path).exists():
            mode = "upload"
        else:
            mode = "query"

        # åˆå§‹åŒ–çŠ¶æ€
        initial_state = KnowledgeQAState(
            query=query,
            file_path=file_path,
            mode=mode,
            context_docs=[],
            reader_result=None,
            qa_answer="",
            verify_state=None,
            finished_state=None,
            suggestions=None,
            sources=[],
            error=None,
            iteration_count=0
        )

        # æ‰§è¡Œå›¾
        final_state = self.app.invoke(initial_state)

        # è¿”å›ç»“æœ
        result = {
            "answer": final_state["qa_answer"],
            "sources": final_state["sources"],
            "mode": final_state["mode"],
            "iteration_count": final_state.get("iteration_count", 0),
            "finished_state": final_state.get("finished_state"),
            "verify_state": final_state.get("verify_state")
        }

        log.info("è¾“å…¥å¤„ç†å®Œæˆ")
        return result

    @traceable(name="chat_streaming")
    def chat_streaming(self, query: str, file_path: Optional[str] = None):
        """æµå¼å¯¹è¯æ¥å£"""
        log.info(f"å¼€å§‹æµå¼å¤„ç†ç”¨æˆ·è¾“å…¥ - æŸ¥è¯¢: {query}, æ–‡ä»¶: {file_path}")

        # ç¡®å®šæ¨¡å¼
        if file_path and Path(file_path).exists():
            mode = "upload"
        else:
            mode = "query"

        # åˆå§‹åŒ–çŠ¶æ€
        state = KnowledgeQAState(
            query=query,
            file_path=file_path,
            mode=mode,
            context_docs=[],
            reader_result=None,
            qa_answer="",
            verify_state=None,
            finished_state=None,
            suggestions=None,
            sources=[],
            error=None,
            iteration_count=0
        )

        # å¦‚æœæœ‰æ–‡ä»¶ï¼Œå…ˆå¤„ç†æ–‡ä»¶
        if mode == "upload":
            # å‘é€æ–‡ä»¶å¤„ç†çŠ¶æ€
            yield {"status": "æ­£åœ¨å¤„ç†æ–‡ä»¶...", "type": "status"}
            state = self._process_file_node(state)
            if not state.get("error"):
                yield {"status": "æ­£åœ¨å­˜å‚¨æ–‡æ¡£...", "type": "status"}
                state = self._store_document_node(state)

        # å¦‚æœæœ‰æŸ¥è¯¢ï¼Œè¿›è¡ŒçŸ¥è¯†æ£€ç´¢
        if mode == "query":
            yield {"status": "æ­£åœ¨æ£€ç´¢ç›¸å…³çŸ¥è¯†...", "type": "status"}
            state = self._retrieve_context_node(state)

        # å¼€å§‹ç”Ÿæˆå›ç­”
        yield {"status": "æ­£åœ¨ç”Ÿæˆå›ç­”...", "type": "status"}

        # ä½¿ç”¨LLMçš„æµå¼æ¥å£
        sources = []
        for chunk in self.qa_llm.streaming(query, state["context_docs"]):
            if isinstance(chunk, dict):
                # æœ€åçš„å…ƒæ•°æ®ï¼Œæ·»åŠ  mode ä¿¡æ¯
                chunk["mode"] = mode
                yield chunk
            else:
                # æµå¼æ–‡æœ¬å†…å®¹
                yield chunk

    def clear_memory(self):
        """æ¸…ç©ºå„LLMçš„è®°å¿†"""
        self.qa_llm.clear_memory()
        self.reader_llm.clear_memory()
        log.info("å„LLMè®°å¿†å·²æ¸…ç©º")


if __name__ == "__main__":
    # æµ‹è¯•å‘½ä»¤ï¼Œæ ¹ç›®å½•è·¯å¾„è¿è¡Œï¼šuv run python -m src.knowledge_qa.agent
    print("="*100)
    print("çŸ¥è¯†åº“é—®ç­”Agent - ç«¯åˆ°ç«¯æµ‹è¯•")
    print("="*100)

    print("1. åˆå§‹åŒ–Agent")
    agent = KnowledgeQAAgent()
    print("   Agentåˆå§‹åŒ–å®Œæˆ\n")

    # print("2. æµ‹è¯•æ–‡ä»¶ä¸Šä¼ å¤„ç†")
    # file_path = "examples/å‡¡äººä¿®ä»™ä¼ test.txt"
    # print(f"   ä¸Šä¼ æ–‡ä»¶: {file_path}")
    # result_upload = agent.chat("", file_path=file_path)
    # print(f"   æ¨¡å¼: {result_upload['mode']}\n")

    print("3. æµ‹è¯•çº¯æŸ¥è¯¢å¯¹è¯")
    query1 = "éŸ©ç«‹æ˜¯å¦‚ä½•è¿›å…¥ä¸ƒç„é—¨çš„ï¼Ÿè®°åå¼Ÿå­åˆæ¬¡è€ƒéªŒåŒ…å«å“ªäº›å…³é”®è·¯æ®µä¸ç¯èŠ‚ï¼Ÿ"
    query1 = "å¢¨å¤§å¤«çš„çœŸå®æ¥å†ä¸æ ¸å¿ƒç›®çš„æ˜¯ä»€ä¹ˆï¼Ÿä»–ä¸éŸ©ç«‹å…³ç³»çš„è½¬æŠ˜ç‚¹å‘ç”Ÿåœ¨å“ªäº›äº‹ä»¶ä¸Šï¼Ÿ"
    query1 = "ç¥æ‰‹è°·ä¸­çš„ç¥ç§˜å°ç“¶å…·å¤‡ä»€ä¹ˆè§„å¾‹ä¸ç”¨é€”ï¼ŸéŸ©ç«‹å¦‚ä½•éªŒè¯å¹¶åº”ç”¨ï¼Ÿ"
    query1 = "è½æ—¥å³°â€œæ­»å¥‘è¡€æ–—â€å‰åçš„å…³é”®äººç‰©ä¸è½¬æŠ˜æ˜¯ä»€ä¹ˆï¼ŸéŸ©ç«‹å¦‚ä½•æ‰­è½¬æˆ˜å±€ï¼Ÿ"
    query1 = "éŸ©ç«‹å·²ç³»ç»ŸæŒæ¡çš„æ³•æœ¯ä¸å…¶å±€é™æ˜¯ä»€ä¹ˆï¼Ÿä»–å¦‚ä½•â€œæ³•æ­¦å¹¶ç”¨â€ï¼Ÿ"
    # query1 = "äººç±»ï¼ˆHumanï¼‰çš„æ ‡å‡†ç§æ—ç‰¹æ€§é‡Œï¼Œèƒ½åŠ›å€¼ï¼ˆAbility Scoresï¼‰å¦‚ä½•æ”¹å˜ï¼Ÿäººç±»è¿˜ä¼šè·å¾—å“ªäº›è¯­è¨€ï¼Ÿ"
    # query1 = "åœ¨æˆ˜æ–—ä¸­å½“ä½ ä½¿ç”¨ä¸€æ¬¡â€œåŠ¨ä½œï¼ˆActionï¼‰â€æ—¶ï¼Œä¸‹é¢å“ªé¡¹ä¸æ˜¯æ ‡å‡†åŠ¨ä½œï¼Ÿï¼ˆAï¼‰Dashï¼ˆå†²åˆºï¼‰ ï¼ˆBï¼‰Disengageï¼ˆè„±ç¦»ï¼‰ ï¼ˆCï¼‰Dodgeï¼ˆèº²é—ªï¼‰ ï¼ˆDï¼‰Teleportï¼ˆç¬ç§»ï¼‰"
    # query1 = "å¦‚æœä½ åœ¨æŸå›åˆç”¨ bonus actionï¼ˆå¥–åŠ±åŠ¨ä½œï¼‰æ–½æ”¾äº†ä¸€ä¸ªæ³•æœ¯ï¼Œä½ è¿˜èƒ½åœ¨åŒä¸€å›åˆå†æ–½æ”¾ä¸€ä¸ªéæˆæ³•ï¼ˆcantripï¼‰çš„æ³•æœ¯å—ï¼Ÿä¸ºä»€ä¹ˆï¼Ÿ"
    # query1 = "ç®€è¿°çŸ­ä¼‘æ¯ï¼ˆShort Restï¼‰ä¸é•¿ä¼‘æ¯ï¼ˆLong Restï¼‰çš„ä¸»è¦åŒºåˆ«ä¸æ•ˆæœï¼ˆè‡³å°‘åŒ…å«å„è‡ªæŒç»­æ—¶é—´ä¸æ¢å¤å†…å®¹ï¼‰ã€‚"
    # query1 = "å½“ä¸€ä¸ªç›®æ ‡å¤„äº Grappledï¼ˆè¢«æ“’æŠ±/ç¼ ä½ï¼‰çŠ¶æ€æ—¶ï¼Œä¼šå‘ç”Ÿä»€ä¹ˆï¼Ÿåˆ—å‡ºè¯¥çŠ¶æ€å¯¹ç›®æ ‡çš„å…·ä½“æœºæ¢°æ•ˆæœã€‚"
    print(f"   Q: {query1}")
    result1 = agent.chat(query1)
    print(f"   A: {result1['answer']}")
    print(f"   æ¨¡å¼: {result1['mode']}\n")

    print("\nâœ… Agentæµ‹è¯•å®Œæˆ!")
